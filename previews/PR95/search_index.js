var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PartiallySeparableNLPModels, ModAbstractPSNLPModels, Utils, Meta, ModPBFGSNLPModels, ModPCSNLPModels, ModPLBFGSNLPModels, ModPLSENLPModels, ModPLSR1NLPModels, ModPSENLPModels, ModPSNLPModels, ModPSR1NLPModels, PartitionedBackends]","category":"page"},{"location":"reference/#NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractPQNNLPModel{T, S}, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate ∇f(x), the gradient of the objective function at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{PartiallySeparableNLPModels.ModAbstractPSNLPModels.AbstractPartiallySeparableNLPModel{T, S}, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate ∇f(x), the gradient of the objective function at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad-Union{Tuple{S}, Tuple{T}, Tuple{AbstractPQNNLPModel{T, S}, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.grad","text":"g = grad(nlp, x)\n\nEvaluate ∇f(x), the gradient of the objective function at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad-Union{Tuple{S}, Tuple{T}, Tuple{PartiallySeparableNLPModels.ModAbstractPSNLPModels.AbstractPartiallySeparableNLPModel{T, S}, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.grad","text":"g = grad(nlp, x)\n\nEvaluate ∇f(x), the gradient of the objective function at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractPQNNLPModel{T, S}, S, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.hprod!","text":"hprod!(nlp::AbstractPQNNLPModel, x::AbstractVector, v::AbstractVector, Hv::AbstractVector; obj_weight=1.)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!-Union{Tuple{S}, Tuple{T}, Tuple{PartiallySeparableNLPModels.ModAbstractPSNLPModels.AbstractPartiallySeparableNLPModel{T, S}, S, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.hprod!","text":"hprod!(nlp::AbstractPartiallySeparableNLPModel, x::AbstractVector, v::AbstractVector, Hv::AbstractVector; obj_weight=1.)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractPQNNLPModel{T, S}, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.hprod","text":"hprod!(nlp::AbstractPQNNLPModel, x::AbstractVector, v::AbstractVector, Hv::AbstractVector; obj_weight=1.)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Union{Tuple{S}, Tuple{T}, Tuple{PartiallySeparableNLPModels.ModAbstractPSNLPModels.AbstractPartiallySeparableNLPModel{T, S}, S, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.hprod","text":"hprod!(nlp::AbstractPartiallySeparableNLPModel, x::AbstractVector, v::AbstractVector, Hv::AbstractVector; obj_weight=1.)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{AbstractPQNNLPModel{T, S}, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{PartiallySeparableNLPModels.ModAbstractPSNLPModels.AbstractPartiallySeparableNLPModel{T, S}, S}} where {T, S<:AbstractVector{T}}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.ModAbstractPSNLPModels.SupportedNLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModAbstractPSNLPModels.SupportedNLPModel","text":"Accumulate the supported NLPModels. \n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModAbstractPSNLPModels.ElementFunction","page":"Reference","title":"PartiallySeparableNLPModels.ModAbstractPSNLPModels.ElementFunction","text":"ElementFunction\n\nA type that gathers the information indentifying an element function in a PartiallySeparableNLPModel, and its properties. ElementFunction has fields:\n\ni: the index of the element function;\nindex_element_tree: the index occupied in the element-function vector after the deletion of redundant element functions;\nvariable_indices: list of elemental variables of ElementFunction;\ntype: constant, linear, quadratic, cubic or general;\nconvexity_status: constant, linear, convex, concave or unknown.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.Utils.distinct_element_expr_tree-Union{Tuple{T}, Tuple{Vector{T}, Vector{Vector{Int64}}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.Utils.distinct_element_expr_tree","text":"(element_expr_trees, indices_element_tree) = distinct_element_expr_tree(vec_element_expr_tree::Vector{T}, vec_element_variables::Vector{Vector{Int}}; N::Int = length(vec_element_expr_tree)) where {T}\n\nIn practice, there may have several element functions having the same expression tree. distinct_element_expr_tree filters the vector vec_element_expr_tree to return element_expr_trees the distincts element functions. length(element_expr_trees) == M < N == length(vec_element_expr_tree). In addition it returns indices_element_tree, who records the index (1 <= i <= M) related ot the expression tree of each element function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.Utils.merge_linear_elements-Tuple{Vector{ExpressionTreeForge.M_implementation_tree.Type_node{ExpressionTreeForge.M_abstract_expr_node.Abstract_expr_node}}, Int64}","page":"Reference","title":"PartiallySeparableNLPModels.Utils.merge_linear_elements","text":"(vec_element_functions, N, linear_vector) = merge_linear_elements(vec_element_functions::Vector{ExpressionTreeForge.Type_expr_tree}, N::Int)\n\nMerge every linear element function from vec_element_functions into a single one. Return the new adequate vec_element_functions, N and linear_vector::Vector{Bool} of size N indicating with true which element is linear. If the method runs correctly, only linear_vector[N] may be set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.Utils.partitioned_structure-Union{Tuple{G}, Tuple{Union{NLPModelsJuMP.MathOptNLPModel, ADNLPModels.ADNLPModel}, G, Int64}} where G","page":"Reference","title":"PartiallySeparableNLPModels.Utils.partitioned_structure","text":"partitioned_structure = build_PartitionedDataTRPQN(expr_tree, n)\n\nReturn the structure required to run a partitioned quasi-Newton trust-region method.  It finds the partially-separable structure of an expression tree expr_tree representing f(x) = ∑fᵢ(xᵢ). Then it allocates the partitioned structures required. To define properly the sparse matrix of the partitioned matrix we need the size of the problem: n.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.Meta.partitioned_meta-Union{Tuple{T}, Tuple{NLPModels.NLPModelMeta{T, Vector{T}}, PartitionedVectors.PartitionedVector{T}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.Meta.partitioned_meta","text":"meta = partitioned_meta(meta::NLPModels.NLPModelMeta{T, Vector{T}}, x0::PartitionedVector{T})\n\nReturn an NLPModelMeta dedicated to PartitionedVectors, i.e. meta.x0 is a PartitionedVector.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.ModPBFGSNLPModels.PBFGSNLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPBFGSNLPModels.PBFGSNLPModel","text":"PBFGSNLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using partitioned BFGS Hessian approximation. PBFGSNLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PBFGSNLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPCSNLPModels.PCSNLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPCSNLPModels.PCSNLPModel","text":"PCSNLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using a PCS Hessian approximation. PCSNLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PCSNLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPLBFGSNLPModels.PLBFGSNLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPLBFGSNLPModels.PLBFGSNLPModel","text":"PLBFGSNLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using a PLBFGS Hessian approximation. PLBFGSNLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PLBFGSNLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPLSENLPModels.PLSENLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPLSENLPModels.PLSENLPModel","text":"PLSENLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using a PLSE Hessian approximation. PLSENLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PLSENLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPLSR1NLPModels.PLSR1NLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPLSR1NLPModels.PLSR1NLPModel","text":"PLSR1NLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using a PLSR1 Hessian approximation. PLSR1NLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PLSR1NLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPSENLPModels.PSENLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPSENLPModels.PSENLPModel","text":"PSENLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using a PSE Hessian approximation. PSENLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PSENLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPSNLPModels.PSNLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPSNLPModels.PSNLPModel","text":"PSNLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using partitioned hessian-vector product. PSNLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PSNLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.ModPSR1NLPModels.PSR1NLPModel","page":"Reference","title":"PartiallySeparableNLPModels.ModPSR1NLPModels.PSR1NLPModel","text":"PSR1NLPModel{G, T, S, M <: AbstractNLPModel{T, S}, Meta <: AbstractNLPModelMeta{T, S},} <: AbstractPQNNLPModel{T,S}\n\nDeduct and allocate the partitioned structures of a NLPModel using partitioned SR1 Hessian approximation. PSR1NLPModel has fields:\n\nmodel: the original model;\nmeta: gather information about the PSR1NLPModel;\ncounters: count how many standards methods of NLPModels are called;\nn: the size of the problem;\nN: the number of element functions;\nvec_elt_fun: a ElementFunction vector, of size N;\nM: the number of distinct element-function expression trees;\nvec_elt_complete_expr_tree: a Complete_expr_tree vector, of size M;\nelement_expr_tree_table: a vector of size M, the i-th element element_expr_tree_table[i]::Vector{Int} informs which element functions use the vec_elt_complete_expr_tree[i] expression tree;\nindex_element_tree: a vector of size N where each component indicates which Complete_expr_tree from vec_elt_complete_expr_tree is used for the corresponding element;\nvec_compiled_element_gradients: the vector gathering the compiled tapes for every element gradient evaluations;\nop: the partitioned matrix (main memory cost);\nname: the name of partitioned quasi-Newton update performed\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementMOIModelBackend","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementMOIModelBackend","text":"ElementMOIModelBackend{T}\n\nComposed of:\n\nvec_element_evaluators::Vector{MOI.Nonlinear.Evaluator{MOI.Nonlinear.ReverseAD.NLPEvaluator}}, M distinct element function MOI.Nonlinear.Model;\nindex_element_tree::Vector{Int}, from which any of the N element function may associate a gradient tape from vec_element_gradient_tapes.\n\nEach MOI.Nonlinear.Evaluator{MOI.Nonlinear.ReverseAD.NLPEvaluator} accumulates the element-function's contribution in a element-vector of a PartitionedVector.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementMOIModelBackend-Union{Tuple{T}, Tuple{Vector, Vector{Int64}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementMOIModelBackend","text":"backend = ElementMOIModelBackend(vec_elt_expr_tree::Vector, index_element_tree::Vector{Int}; type=Float64)\n\nReturn an ElementMOIModelBackend from a Vector of expression trees (supported by ExpressionTreeForge.jl) of size length(vec_elt_expr_tree)=M and index_element_tree which redirects each element function i  to its corresponding expression tree (1 ≤ index_element_tree[i] ≤ M, 1 ≤ i ≤ N).\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementReverseDiffGradient","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementReverseDiffGradient","text":"ElementReverseDiffGradient{T}\n\nComposed of:\n\nvec_element_gradient_tapes::Vector{ReverseDiff.CompiledTape}, M distinct element function tapes;\nindex_element_tree::Vector{Int}, from which any of the N element function may associate a gradient tape from vec_element_gradient_tapes.\n\nEach ReverseDiff.CompiledTape accumulates the element-function's contribution in a element-vector of a PartitionedVector.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementReverseDiffGradient-Union{Tuple{T}, Tuple{Vector, Vector{Int64}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementReverseDiffGradient","text":"gradient_brackend = ElementReverseDiffGradient(vec_elt_expr_tree::Vector, index_element_tree::Vector{Int}; type::Type{T}=Float64) where {T}\n\nReturn an ElementReverseDiffGradient from a Vector of expression trees (supported by ExpressionTreeForge.jl) of size length(vec_elt_expr_tree)=M and index_element_tree which redirects each element function i  to its corresponding expression tree (1 ≤ index_element_tree[i] ≤ M, 1 ≤ i ≤ N).\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementReverseForwardHprod","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementReverseForwardHprod","text":"ElementReverseForwardHprod{T,G}\n\nCompute the partitioned Hessian-product with partitioned_hessian_prod! by applying successively ReverseDiff and ForwardDiff. It is composed of:\n\nvec_elt_complete_expr_tree::Vector{G}, the expression trees of the distinct element functions (of size M);\nindex_element_tree::Vector{Int}, reffering to index in vec_elt_complete_expr_tree of any of the N element function;\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ElementReverseForwardHprod-Union{Tuple{G}, Tuple{T}, Tuple{Vector{G}, Vector{Int64}}} where {T, G}","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ElementReverseForwardHprod","text":"hprod_backend = ElementReverseForwardHprod(complete_trees::Vector, index_element_tree::Vector{Int}; type=Float64)\n\nReturn an ElementReverseForwardHprod from a Vector of expression trees (supported by ExpressionTreeForge.jl) vec_elt_expr_tree of size length(vec_elt_expr_tree)=M and index_element_tree which redirects each element function i  to its corresponding expression tree (1 ≤ index_element_tree[i] ≤ M, 1 ≤ i ≤ N).\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.MOIObjectiveBackend","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.MOIObjectiveBackend","text":"MOIObjectiveBackend{T, Model}\n\nComposed of nlp::Model, it evaluates the objective function from NLPModels.obj(nlp, x::AbstractVector{T}). The user has to make sure nlp is can evaluate x::AbstractVector{T} with a suitable type T.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.MOIObjectiveBackend-Union{Tuple{G}, Tuple{T}, Tuple{G, Int64}} where {T, G}","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.MOIObjectiveBackend","text":"MOIObjectiveBackend(nlp::SupportedNLPModel; type=eltype(nlp.meta.x0))\n\nCreate an objective backend from nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ModifiedObjectiveMOIModelBackend","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ModifiedObjectiveMOIModelBackend","text":"ModifiedObjectiveMOIModelBackend{T}\n\nComposed of:\n\nvec_element_evaluators::Vector{MOI.Nonlinear.Evaluator{MOI.Nonlinear.ReverseAD.NLPEvaluator}}, M distinct element function MOI.Nonlinear.Model;\nindex_element_tree::Vector{Int}, from which any of the N element function may associate a gradient tape from vec_element_gradient_tapes.\n\nEach MOI.Nonlinear.Evaluator{MOI.Nonlinear.ReverseAD.NLPEvaluator} accumulates the element-function's contribution in a element-vector of a PartitionedVector.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.ModifiedObjectiveMOIModelBackend-Union{Tuple{Vector}, Tuple{T}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.ModifiedObjectiveMOIModelBackend","text":"backend = ModifiedObjectiveMOIModelBackend(vec_elt_expr_tree::Vector, index_element_tree::Vector{Int}; type=Float64)\n\nReturn an ModifiedObjectiveMOIModelBackend from a Vector of expression trees (supported by ExpressionTreeForge.jl) of size length(vec_elt_expr_tree)=N and their element variables affiliated. Suppose f(x) = f₁(x) + f₂(x) partially-separable considering the element functions f₁(x) = x₁ * x₂ * x₃² and f₂(x) = x₂ * x₃ * x₄ (N=2), ModifiedObjectiveMOIModelBackend defines a MOI.Nonlinear.Model where F(y) = y₁ * y₂ * y₃² + y₄ * y₅ * y₆ and its evaluator. Each partial derivative of F corresponds to a partial derivative of a single element function fᵢ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.NLPObjectiveBackend","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.NLPObjectiveBackend","text":"NLPObjectiveBackend{T, Model}\n\nComposed of nlp::Model, it evaluates the objective function from NLPModels.obj(nlp, x::AbstractVector{T}). The user has to make sure nlp is can evaluate x::AbstractVector{T} with a suitable type T.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.NLPObjectiveBackend-Union{Tuple{Union{NLPModelsJuMP.MathOptNLPModel, ADNLPModels.ADNLPModel}}, Tuple{T}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.NLPObjectiveBackend","text":"NLPObjectiveBackend(nlp::SupportedNLPModel; type=eltype(nlp.meta.x0))\n\nCreate an objective backend from nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.SparseJacobianMoiModelBackend","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.SparseJacobianMoiModelBackend","text":"SparseJacobianMoiModelBackend{T}\n\nComposed of:\n\nevaluator::MOI.Nonlinear.Evaluator{MOI.Nonlinear.ReverseAD.NLPEvaluator}, an evaluator of a MOI.Nonlinear.Model constrained by every element functions;\nsparse_jacobian::Vector{T}, mandatory to store in place the sparse Jacobianwith MathOptInterface;\ntranslated_x::PartitionedVector{T}, to handle variables translations, especially when the model doesn't depend on every variable.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.SparseJacobianMoiModelBackend-Union{Tuple{T}, Tuple{Vector, Int64}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.SparseJacobianMoiModelBackend","text":"backend = SparseJacobianMoiModelBackend(vec_elt_expr_tree::Vector, n::Int; elemental_variables::Vector{Vector{Int}}), type=Float64)\n\nReturn an SparseJacobianMoiModelBackend from a Vector of expression trees (supported by ExpressionTreeForge.jl) of size length(vec_elt_expr_tree)=N and their element variables affiliated. Suppose f(x) = f₁(x) + f₂(x) partially-separable considering the element functions f₁(x) = x₁ * x₂ * x₃² and f₂(x) = x₂ * x₃ * x₄ (N=2), SparseJacobianMoiModelBackend defines a MOI.Nonlinear.Model having f(x) as the objective f₁ and f₂ as two constraints.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.compiled_grad_element_function-Tuple{G} where G","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.compiled_grad_element_function","text":"element_gradient_tape = compiled_grad_element_function(element_function::T; ni::Int = length(ExpressionTreeForge.get_elemental_variables(element_function)), type = Float64) where {T}\n\nReturn the elment_gradient_tape::GradientTape which speed up the gradient computation of element_function with ReverseDiff.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.objective-Union{Tuple{T}, Tuple{PartiallySeparableNLPModels.PartitionedBackends.PartitionedBackend{T}, AbstractVector{T}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.objective","text":"fx = objective(backend::AbstractObjectiveBackend{T}, x::AbstractVector{T})\n\nCompute the objective value from backend at the point x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.partitioned_gradient!-Union{Tuple{T}, Tuple{PartiallySeparableNLPModels.PartitionedBackends.PartitionedBackend{T}, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.partitioned_gradient!","text":"partitioned_gradient!(backend::AbstractObjectiveBackend{T}, x::AbstractVector{T}, g::AbstractVector{T})\n\nCompute the partitioned gradient from backend at the point x in place of g. This method is designed for PartitionedVector{T}<:AbstractVector{T} (for now, both x and g).\n\n\n\n\n\n","category":"method"},{"location":"reference/#PartiallySeparableNLPModels.PartitionedBackends.partitioned_hessian_prod!-Union{Tuple{T}, Tuple{PartiallySeparableNLPModels.PartitionedBackends.PartitionedBackend{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"PartiallySeparableNLPModels.PartitionedBackends.partitioned_hessian_prod!","text":"partitioned_hessian_prod!(backend::AbstractHprodBackend{T}, x::AbstractVector{T}, v::AbstractVector{T}, Hv::AbstractVector{T})\n\nCompute the partitioned Hessian-vector product ∇² f(x) v from backend in place of Hv. This method is designed for PartitionedVector{T}<:AbstractVector{T} (x, v and Hv).\n\n\n\n\n\n","category":"method"},{"location":"#PartiallySeparableNLPModels:-Exploiting-the-partially-separable-structure-to-define-partitioned-quasi-Newton-NLPModels","page":"Home","title":"PartiallySeparableNLPModels: Exploiting the partially-separable structure to define partitioned quasi-Newton NLPModels","text":"","category":"section"},{"location":"#How-to-cite","page":"Home","title":"How to cite","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use PartiallySeparableNLPModels.jl in your work, please cite using the format given in CITATION.bib.","category":"page"},{"location":"#Philosophy","page":"Home","title":"Philosophy","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The purpose of PartiallySeparableNLPModels.jl is to define automatically partially-separable NLPModels. Moreover, it defines several partitioned quasi-Newton models which are meant to be minimized through solvers from JSOSolvers.jl","category":"page"},{"location":"#Compatibility","page":"Home","title":"Compatibility","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia ≥ 1.6.","category":"page"},{"location":"#How-to-install","page":"Home","title":"How to install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"pkg> add PartiallySeparableNLPModels\npkg> test PartiallySeparableNLPModels","category":"page"},{"location":"#How-to-use","page":"Home","title":"How to use","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the tutorial.","category":"page"},{"location":"#Dependencies","page":"Home","title":"Dependencies","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The module uses ExpressionTreeForge.jl to detect the partially-separable structure, PartitionedStructures.jl to allocate partitioned quasi-Newton approximations and PartitionedVectors.jl to fit the AbstractVector interface mandatory for AbstractNLPModel methods.","category":"page"},{"location":"#Bug-reports-and-discussions","page":"Home","title":"Bug reports and discussions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to ask a question not suited for a bug report, feel free to start a discussion here. This forum is for general discussion about this repository and the JuliaSmoothOptimizers, so questions about any of our packages are welcome.","category":"page"},{"location":"tutorial/#PartiallySeparableNLPModels.jl-Tutorial","page":"Tutorial","title":"PartiallySeparableNLPModels.jl Tutorial","text":"","category":"section"},{"location":"tutorial/#An-NLPModel-exploiting-partial-separability","page":"Tutorial","title":"An NLPModel exploiting partial separability","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"PartiallySeparableNLPModels.jl defines a subtype of AbstractNLPModel to exploit automatically the partially-separable structure of fR^n to R","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":" f(x) = sum_i=1^N f_i (U_i x)   f_i  R^n_i to R  U_i in R^n_i times n n_i ll n","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"as a sum of element functions f_i.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"PartiallySeparableNLPModels.jl relies on ExpressionTreeForge.jl to detect the partially-separable structure. Then, it defines suitable partitioned structures using PartitionedStructures.jl and PartitionedVectors.jl. Any NLPModels from PartiallySeparableNLPModels.jl rely on PartitionedVector <: AbstractVector instead of Vector. Any model from PartiallySeparableNLPModels.jl may be defined either from a ADNLPModel or a MathOptNLPModel. Let starts with an example using an ADNLPModel (MathOptNLPModel will follow):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using PartiallySeparableNLPModels, ADNLPModels\n\nfunction example(x)\n  n = length(x)\n  n < 2 && @error(\"length of x must be >= 2\")\n  return sum((x[i] + x[i+1])^2 for i=1:n-1)\nend \nstart_example(n :: Int) = ones(n)\nexample_model(n :: Int) = ADNLPModel(example, start_example(n), name=\"Example \" * string(n) * \" variables\")\n\nn = 4 # size of the problem\nmodel = example_model(n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and call PSNLPModel <: AbstractPartiallySeparableNLPModel to define a partitioned NLPModel using exact second derivatives:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"psnlp = PSNLPModel(model)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"where psnlp.meta.x0 is a PartitionedVector:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"psnlp.meta.x0","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Then, you can apply the usual methods obj and grad, hprod from NLPModels.jl:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using NLPModels\nx = similar(psnlp.meta.x0)\nx .= 1\nfx = NLPModels.obj(psnlp, x) # compute the objective function","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"gx = NLPModels.grad(psnlp, x) # compute the gradient","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"v = similar(x)\nv .= 1\nhv = NLPModels.hprod(psnlp, x, v)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"fx, gx and hv accumulate contributions from element functions, either its evaluation f_i(U_ix), its gradient nabla f_i(U_ix) or its element Hessian-vector nabla^2 f_i(U_i x) U_i v. You can get the Vector value of gx and hv with ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Vector(hv)\nVector(gx)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and you can find more detail about PartitionedVectors in PartitionedVectors.jl tutorial.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The same procedure can be applied to MathOptNLPModels:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using JuMP, MathOptInterface, NLPModelsJuMP\n\nfunction jump_example(n::Int)\n  m = Model()\n  @variable(m, x[1:n])\n  @NLobjective(m, Min, sum((x[i] + x[i+1])^2 for i = 1:n-1))\n  evaluator = JuMP.NLPEvaluator(m)\n  MathOptInterface.initialize(evaluator, [:ExprGraph])\n  variables = JuMP.all_variables(m)\n  x0 = ones(n)\n  JuMP.set_start_value.(variables, x0)\n  nlp = MathOptNLPModel(m)\n  return nlp\nend\n\njumpnlp = jump_example(n)\npsnlp = PSNLPModel(jumpnlp)\n\nfx = NLPModels.obj(psnlp, x) # compute the objective function\ngx = NLPModels.grad(psnlp, x) # compute the gradient","category":"page"},{"location":"tutorial/#Partitioned-quasi-Newton-NLPModels","page":"Tutorial","title":"Partitioned quasi-Newton NLPModels","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"A model deriving from AbstractPQNNLPModel<:QuasiNewtonModel allocates storage required for partitioned quasi-Newton updates, which are implemented in PartitionedStructures.jl (see the PartitionedStructures.jl tutorial for more details). There are several variants:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"PBFGSNLPModel: every element-Hessian approximation is updated with BFGS;\nPSR1NLPModel: every element-Hessian approximation is updated with SR1;\nPSENLPModel: every element-Hessian approximation is updated with BFGS if the curvature condition holds, or with SR1 otherwise;\nPCSNLPModel: each element-Hessian approximation with BFGS if it is classified as convex, or with SR1 otherwise;\nPLBFGSNLPModel: every element-Hessian approximations is a LBFGS operator;\nPLSR1NLPModel: every element-Hessian approximations is a LSR1 operator;\nPLSENLPModel: by default, every element-Hessian approximations is a LBFGS operator as long as the curvature condition holds, otherwise it becomes a LSR1 operator.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"pbfgsnlp = PBFGSNLPModel(jumpnlp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The Hessian approximation of each element function f_i (y) = (y_1 + y_2)^2 is initially set to an identity matrix.  The contribution of every element Hessian approximation is accumulated as","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"left \nbeginarrayccc\n  left ( beginarraycc\n    1  \n     1  \n  endarray right )   \n   0  \n    0 \nendarray\nright  \n+ \nleft \nbeginarrayccc\n  0   \n   left ( beginarraycc\n    1  \n     1  \n  endarray right )  \n    0 \nendarray\nright \n+ \nleft \nbeginarrayccc\n  0   \n   0  \n    left ( beginarraycc\n    1  \n     1  \n  endarray right )\nendarray\nright ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The accumulated matrix can be visualized with:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Matrix(pbfgsnlp.op)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Then, you can update the partitioned quasi-Newton approximation with the pair y,s:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"s = similar(x)\ns .= 0.5\ny = grad(pbfgsnlp, x+s) - grad(pbfgsnlp, x)\npush!(pbfgsnlp, y, s)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and you can perform a partitioned-matrix-vector product with:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Bv = hprod(pbfgsnlp, x, s)\nVector(Bv)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Finally, you can build a TrunkSolver (from JSOSolvers) from a PartiallySeparableNLPModel:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using JSOSolvers\n\ntrunk_solver = TrunkSolver(pbfgsnlp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"which define properly the PartitionedVectors mandatory for running trunk turnk_solver can be solve afterward with:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"solve!(trunk_solver, pbfgsnlp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For now, TrunkSolver is the sole Solver defined for PartiallySeparableNLPModels, if you want to add another Solver, you should define it similarly to TrunkSolver in src/trunk.jl.","category":"page"}]
}
